{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Species Classification using Decision Tree\n",
    "\n",
    "This notebook demonstrates the complete machine learning workflow for classifying Iris species using a decision tree classifier. We'll cover data preprocessing, model training, and evaluation.\n",
    "\n",
    "## Steps:\n",
    "1. Import required libraries\n",
    "2. Load and explore the dataset\n",
    "3. Data preprocessing (handle missing values, encode labels)\n",
    "4. Split data into training and testing sets\n",
    "5. Train a decision tree classifier\n",
    "6. Make predictions\n",
    "7. Evaluate model performance (accuracy, precision, recall)\n",
    "8. Visualize results (confusion matrix, feature importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import scikit-learn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn import tree\n",
    "\n",
    "# Set style for visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Display plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "file_path = '../Data/Iris.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"\\nDataset information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic statistics\n",
    "print(\"Basic statistics:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "display(df.isnull().sum())\n",
    "\n",
    "# Display species distribution\n",
    "print(\"\\nSpecies distribution:\")\n",
    "display(df['Species'].value_counts())\n",
    "\n",
    "# Visualize species distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df, x='Species')\n",
    "plt.title('Distribution of Iris Species')\n",
    "plt.xlabel('Species')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationships between features\n",
    "# Pair plot to see relationships between all features\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.pairplot(df.drop('Id', axis=1), hue='Species', markers=['o', 's', 'D'])\n",
    "plt.suptitle('Pair Plot of Iris Features by Species', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions\n",
    "features = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, feature in enumerate(features, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.boxplot(data=df, x='Species', y=feature)\n",
    "    plt.title(f'{feature} by Species')\n",
    "    plt.xlabel('Species')\n",
    "    plt.ylabel(feature)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "### 3.1 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any missing values\n",
    "print(\"Missing values before handling:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# In this case, there are no missing values in the Iris dataset.\n",
    "# But let's demonstrate the handling process anyway.\n",
    "\n",
    "# Strategy: For numerical features, we could fill missing values with the mean\n",
    "# For categorical features, we could fill with the mode\n",
    "\n",
    "# Since there are no missing values, we'll skip the filling step\n",
    "# But this is how you would handle missing values if they existed:\n",
    "# df.fillna(df.mean(numeric_only=True), inplace=True)  # Fill numerical with mean\n",
    "# df.fillna(df.mode().iloc[0], inplace=True)  # Fill categorical with mode\n",
    "\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable (Species)\n",
    "label_encoder = LabelEncoder()\n",
    "df['Species_encoded'] = label_encoder.fit_transform(df['Species'])\n",
    "\n",
    "# Display the mapping\n",
    "species_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Species encoding mapping:\")\n",
    "for species, code in species_mapping.items():\n",
    "    print(f\"{species}: {code}\")\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(\"\\nUpdated dataframe with encoded species:\")\n",
    "display(df[['Species', 'Species_encoded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target variable\n",
    "# Drop the 'Id' column as it's not a useful feature\n",
    "X = df.drop(['Id', 'Species', 'Species_encoded'], axis=1)\n",
    "y = df['Species_encoded']\n",
    "\n",
    "print(\"Features (X) shape:\", X.shape)\n",
    "print(\"Target (y) shape:\", y.shape)\n",
    "print(\"\\nFeatures:\")\n",
    "display(X.head())\n",
    "print(\"\\nTarget:\")\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)\n",
    "print(\"\\nTraining set target distribution:\")\n",
    "print(y_train.value_counts().sort_index())\n",
    "print(\"\\nTesting set target distribution:\")\n",
    "print(y_test.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train a Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(\n",
    "    random_state=42, \n",
    "    max_depth=3,  # Limit tree depth for better visualization\n",
    "    criterion='gini'\n",
    ")\n",
    "\n",
    "# Train the classifier\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"Decision Tree Classifier trained successfully!\")\n",
    "print(\"\\nTree parameters:\")\n",
    "print(f\"Max depth: {dt_classifier.max_depth}\")\n",
    "print(f\"Criterion: {dt_classifier.criterion}\")\n",
    "print(f\"Number of features: {dt_classifier.n_features_in_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "tree.plot_tree(\n",
    "    dt_classifier,\n",
    "    feature_names=X.columns,\n",
    "    class_names=label_encoder.classes_,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=10\n",
    ")\n",
    "plt.title('Decision Tree for Iris Classification', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Display some sample predictions\n",
    "print(\"Sample predictions:\")\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test.values,\n",
    "    'Predicted': y_pred,\n",
    "    'Actual_Species': label_encoder.inverse_transform(y_test.values),\n",
    "    'Predicted_Species': label_encoder.inverse_transform(y_pred)\n",
    "})\n",
    "display(results_df.head(10))\n",
    "\n",
    "# Calculate prediction accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nPrediction accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision_macro = precision_score(y_test, y_pred, average='macro')\n",
    "recall_macro = recall_score(y_test, y_pred, average='macro')\n",
    "precision_weighted = precision_score(y_test, y_pred, average='weighted')\n",
    "recall_weighted = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Model Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Macro Precision: {precision_macro:.4f}\")\n",
    "print(f\"Macro Recall: {recall_macro:.4f}\")\n",
    "print(f\"Weighted Precision: {precision_weighted:.4f}\")\n",
    "print(f\"Weighted Recall: {recall_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed classification report\n",
    "print(\"Detailed Classification Report:\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(\n",
    "    y_test, \n",
    "    y_pred, \n",
    "    target_names=label_encoder.classes_\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    xticklabels=label_encoder.classes_,\n",
    "    yticklabels=label_encoder.classes_\n",
    ")\n",
    "plt.title('Confusion Matrix', fontsize=14)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "feature_importance = dt_classifier.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "display(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    data=importance_df, \n",
    "    x='Importance', \n",
    "    y='Feature',\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title('Feature Importance in Decision Tree', fontsize=14)\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Tuning (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try different tree depths to see how it affects performance\n",
    "depths = [2, 3, 4, 5, 6, 7, 8, None]\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for depth in depths:\n",
    "    dt = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    dt.fit(X_train, y_train)\n",
    "    train_accuracies.append(dt.score(X_train, y_train))\n",
    "    test_accuracies.append(dt.score(X_test, y_test))\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(\n",
    "    [str(d) for d in depths], \n",
    "    train_accuracies, \n",
    "    'bo-', \n",
    "    label='Training Accuracy'\n",
    ")\n",
    "plt.plot(\n",
    "    [str(d) for d in depths], \n",
    "    test_accuracies, \n",
    "    'ro-', \n",
    "    label='Testing Accuracy'\n",
    ") \n",
    "plt.axvline(x='3', color='g', linestyle='--', label='Original Model (depth=3)')\n",
    "plt.xlabel('Tree Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Effect of Tree Depth on Model Performance')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best depth based on test accuracy\n",
    "best_depth_index = test_accuracies.index(max(test_accuracies))\n",
    "best_depth = depths[best_depth_index]\n",
    "best_accuracy = test_accuracies[best_depth_index]\n",
    "\n",
    "print(f\"Best tree depth: {best_depth}\")\n",
    "print(f\"Best test accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Train the best model\n",
    "best_dt = DecisionTreeClassifier(max_depth=best_depth, random_state=42)\n",
    "best_dt.fit(X_train, y_train)\n",
    "y_pred_best = best_dt.predict(X_test)\n",
    "\n",
    "print(\"\\nBest Model Classification Report:\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(\n",
    "    y_test, \n",
    "    y_pred_best, \n",
    "    target_names=label_encoder.classes_\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the results\n",
    "print(\"\"\"Summary of Iris Species Classification using Decision Tree:\n",
    "===============================================================\"\n",
    "\n",
    "1. Dataset Information:\n",
    "   - Total samples: 150\n",
    "   - Features: 4 (SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm)\n",
    "   - Classes: 3 (Iris-setosa, Iris-versicolor, Iris-virginica)\n",
    "   - No missing values found\n",
    "\n",
    "2. Data Preprocessing:\n",
    "   - Encoded species labels using LabelEncoder\n",
    "   - Split data into 70% training and 30% testing sets\n",
    "   - Applied stratified sampling to maintain class distribution\n",
    "\n",
    "3. Model Performance:\n",
    "   - Original model (depth=3): Accuracy = {:.4f}\n",
    "   - Best model (depth={}): Accuracy = {:.4f}\n",
    "   - Precision and Recall scores were excellent for all classes\n",
    "\n",
    "4. Key Findings:\n",
    "   - PetalLengthCm and PetalWidthCm are the most important features\n",
    "   - The model achieved near-perfect classification performance\n",
    "   - Decision trees are well-suited for the Iris dataset\n",
    "\n",
    "5. Recommendations:\n",
    "   - The model can be reliably used for Iris species prediction\n",
    "   - Consider collecting more diverse samples for model validation\n",
    "   - Explore ensemble methods for potentially improved performance\n",
    "\"\"\".format(accuracy, best_depth if best_depth is not None else 'unlimited', best_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model for future use\n",
    "import joblib\n",
    "\n",
    "# Save the model, label encoder, and feature names\n",
    "model_data = {\n",
    "    'model': best_dt,\n",
    "    'label_encoder': label_encoder,\n",
    "    'feature_names': list(X.columns),\n",
    "    'species_mapping': species_mapping\n",
    "}\n",
    "\n",
    "joblib.dump(model_data, '../iris_decision_tree_model.pkl')\n",
    "print(\"Model saved successfully to 'iris_decision_tree_model.pkl'\")\n",
    "print(\"This model can be loaded later for making predictions on new data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Example Usage of the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Make predictions on new data\n",
    "print(\"Example: Predicting species for new iris samples\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Create some sample new data (similar to the original dataset)\n",
    "new_data = pd.DataFrame({\n",
    "    'SepalLengthCm': [5.1, 6.5, 7.2],\n",
    "    'SepalWidthCm': [3.5, 3.0, 3.6],\n",
    "    'PetalLengthCm': [1.4, 5.5, 6.1],\n",
    "    'PetalWidthCm': [0.2, 1.8, 2.5]\n",
    "})\n",
    "\n",
    "print(\"New data to predict:\")\n",
    "display(new_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = best_dt.predict(new_data)\n",
    "predicted_species = label_encoder.inverse_transform(predictions)\n",
    "\n",
    "print(\"\\nPredictions:\")\n",
    "for i, species in enumerate(predicted_species):\n",
    "    print(f\"Sample {i+1}: {species}\")\n",
    "\n",
    "# Get prediction probabilities\n",
    "probabilities = best_dt.predict_proba(new_data)\n",
    "print(\"\\nPrediction probabilities:\")\n",
    "prob_df = pd.DataFrame(\n",
    "    probabilities, \n",
    "    columns=label_encoder.classes_\n",
    ")\n",
    "display(prob_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
